<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The future of OCR is not to use OCR! | Gustavo Führ </title> <meta name="author" content="Gustavo Führ"> <meta name="description" content="End-to-end document understanding will be huge."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://gustavofuhr.github.io/blog/2024/ocr-future/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Gustavo Führ </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repos </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The future of OCR is not to use OCR!</h1> <p class="post-meta"> Created in April 20, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/ocr"> <i class="fa-solid fa-hashtag fa-sm"></i> ocr</a>   <a href="/blog/tag/document-understanding"> <i class="fa-solid fa-hashtag fa-sm"></i> document-understanding</a>   <a href="/blog/tag/computer-vision"> <i class="fa-solid fa-hashtag fa-sm"></i> computer-vision</a>   ·   <a href="/blog/category/posts"> <i class="fa-solid fa-tag fa-sm"></i> posts</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ocr_future_img1-480.webp 480w,/assets/img/ocr_future_img1-800.webp 800w,/assets/img/ocr_future_img1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/ocr_future_img1.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Image taken from [1], Donut paper. </div> <p>Around 3-4 years ago, some colleagues and I launched a product that cleverly used OCR outputs to retrieve information from document images. We usually explain that this product was intended for generic documents, meaning it was not trained for a specific layout or style. With a few simple rules (such as: give me the text below the label “Nome”) you can extract a structure JSON containing the most important information from these documents.</p> <p>The set of possible “rules” was pre-defined and mainly related to the OCRs positions and text without fully understanding them. Looking back, we failed to estimate how hard it was for users to create good rules for extracting the required information. Also, the pipeline for extracting info was very complex, resembling this:</p> <p>Get image -&gt; Detect text boxes -&gt; Read OCR -&gt; Aggregate OCR into blocks, lines -&gt; Apply rules for document -&gt; Output JSON.</p> <p>It was also difficult to adapt these pipelines to other important information that might be interesting to extract, such as checkmarks in forms and signatures.</p> <p>Some very cool methods for OCR-free document understanding appeared in the past few years. One of the first was Donut [1], by Clova (which also provided awesome OCRs and text detectors in the past). The idea was to go from the image to a JSON output with a single end-to-end model: Get image -&gt; Apply fine-tuned model for a given task -&gt; Output JSON. The presented results are impressive. The model is composed of an image encoder and text decoder built using transformers. The training is done (as it seems to be the norm these days) in two stages. First, in the pre-training phase, the task is to predict masked text in images (an objective analogous to OCR).</p> <p>Later the model is fine-tuned to a specific task, such as:</p> <ul> <li>document classification, i.e.: what kind of document it is?</li> <li>key information extraction, e.g.: extract the store address from this invoice</li> <li>VQA (Visual Question Answering), a generic question such as “Which is the document’s holder birthday?”</li> </ul> <p>This kind of solution is much more versatile and easy to implement in a product.</p> <p>To not extend this further, these are some other cool related works that I found: Dessurt [2]: similar to Donut, made around the same time, with less impressive results. Pix2Struct [3]: an extension of Donut for dealing with any type of image (documents, screenshots, UI). The pre-training was done with 80M screenshots of HTML images and the object was to predict the HTML of these images. How clever was that? ScreenAI [4]: a recent work from Google that tackles QA, UI navigation, etc. It uses LLMs to create huge annotated datasets. Can you imagine a Siri that actually can be useful and use apps?</p> <p>That’s it this week, let me know what you think.</p> <h2 id="references">References</h2> <p><em>[1] - Kim, Geewook, et al. “Ocr-free document understanding transformer.” European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022.</em></p> <p><em>[2] - Davis, Brian, et al. “End-to-end document recognition and understanding with dessurt.” European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022.</em></p> <p><em>[3] - Lee, Kenton, et al. “Pix2struct: Screenshot parsing as pretraining for visual language understanding.” International Conference on Machine Learning. PMLR, 2023.</em></p> <p><em>[4] - Baechler, Gilles, et al. “ScreenAI: A Vision-Language Model for UI and Infographics Understanding.” arXiv preprint arXiv:2402.04615 (2024).</em></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2017/pushing-the-boundaries-of-face-recognition-systems-by-meerkat-cv-medium/">Pushing the boundaries of Face Recognition systems | by Meerkat Cv | Medium</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2017/a-study-on-beer-logo-detection-and-analysis-on-social-media-by-meerkat-cv-medium/">A study on beer: logo detection and analysis on social media | by Meerkat Cv | Medium</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2017/pushing-the-boundaries-of-face-recognition-systems-by-meerkat-cv-medium/">Pushing the boundaries of Face Recognition systems | by Meerkat Cv | Medium</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/my-favorite-papers-from-cvpr-2022-by-gustavo-fhr-medium/">My favorite papers from CVPR 2022. | by Gustavo Führ | Medium</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/llm-failure/">Caution while using Large Language Models</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Gustavo Führ. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: June 27, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?06cae41083477f121be8cd9797ad8e2f"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>